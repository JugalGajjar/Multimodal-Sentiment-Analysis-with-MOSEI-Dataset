2025-04-23 17:36:22 - root - INFO - Logging to /Users/jugalgajjar/Documents/George Washington University/Semester 2/Machine Learning/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/logs/log.txt
2025-04-23 17:36:22 - root - INFO - All hyperparameters set.
2025-04-23 17:36:22 - root - INFO - Using device: mps
2025-04-23 17:36:22 - root - INFO - Batch size: 32
2025-04-23 17:36:22 - root - INFO - Number of epochs: 2
2025-04-23 17:36:22 - root - INFO - Hidden dimension: 256
2025-04-23 17:36:22 - root - INFO - Number of transformer layers: 4
2025-04-23 17:36:22 - root - INFO - Number of attention heads: 8
2025-04-23 17:36:22 - root - INFO - Dropout rate: 0.3
2025-04-23 17:36:22 - root - INFO - Learning rate: 0.0001
2025-04-23 17:36:22 - root - INFO - Weight decay: 1e-05
2025-04-23 17:36:22 - root - INFO - Early stopping patience: 5
2025-04-23 17:36:22 - root - INFO - Gradient clipping value: 1.0
2025-04-23 17:36:22 - root - INFO - Random seed: 42
2025-04-23 17:36:22 - root - INFO - Log directory: /Users/jugalgajjar/Documents/George Washington University/Semester 2/Machine Learning/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/logs
2025-04-23 17:36:22 - root - INFO - Model save directory: /Users/jugalgajjar/Documents/George Washington University/Semester 2/Machine Learning/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/models
2025-04-23 17:36:22 - root - INFO - Modalities: ['language', 'acoustic', 'visual']
2025-04-23 17:36:22 - root - INFO - Checkpoint: 
2025-04-23 17:36:22 - root - INFO - Random seed set to 42.
2025-04-23 17:36:22 - root - INFO - 
Loading data...
2025-04-23 17:36:22 - src.data.dataset - INFO - Loaded 2370 samples for train split
2025-04-23 17:36:22 - src.data.dataset - INFO - Loaded 264 samples for val split
2025-04-23 17:36:22 - src.data.dataset - INFO - Loaded 658 samples for test split
2025-04-23 17:36:22 - root - INFO - 
Creating model...
2025-04-23 17:36:22 - root - INFO - Model architecture:
TransformerFusionModel(
  (text_encoder): TransformerTextEncoder(
    (input_projection): Linear(in_features=768, out_features=256, bias=True)
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0-3): 4 x TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout): Dropout(p=0.3, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.3, inplace=False)
          (dropout2): Dropout(p=0.3, inplace=False)
        )
      )
    )
    (output_projection): Linear(in_features=256, out_features=1, bias=True)
    (dropout): Dropout(p=0.3, inplace=False)
  )
  (audio_encoder): TransformerAudioEncoder(
    (input_projection): Linear(in_features=40, out_features=128, bias=True)
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0-1): 2 x TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
          )
          (linear1): Linear(in_features=128, out_features=512, bias=True)
          (dropout): Dropout(p=0.3, inplace=False)
          (linear2): Linear(in_features=512, out_features=128, bias=True)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.3, inplace=False)
          (dropout2): Dropout(p=0.3, inplace=False)
        )
      )
    )
    (output_projection): Linear(in_features=128, out_features=1, bias=True)
    (dropout): Dropout(p=0.3, inplace=False)
  )
  (visual_encoder): TransformerVisualEncoder(
    (input_projection): Linear(in_features=35, out_features=128, bias=True)
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0-1): 2 x TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
          )
          (linear1): Linear(in_features=128, out_features=512, bias=True)
          (dropout): Dropout(p=0.3, inplace=False)
          (linear2): Linear(in_features=512, out_features=128, bias=True)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.3, inplace=False)
          (dropout2): Dropout(p=0.3, inplace=False)
        )
      )
    )
    (output_projection): Linear(in_features=128, out_features=1, bias=True)
    (dropout): Dropout(p=0.3, inplace=False)
  )
  (fusion_module): MultimodalCrossAttention(
    (text_proj): Linear(in_features=256, out_features=256, bias=True)
    (audio_proj): Linear(in_features=128, out_features=256, bias=True)
    (visual_proj): Linear(in_features=128, out_features=256, bias=True)
    (text_audio_attn): CrossAttention(
      (query_proj): Linear(in_features=256, out_features=256, bias=True)
      (key_proj): Linear(in_features=256, out_features=256, bias=True)
      (value_proj): Linear(in_features=256, out_features=256, bias=True)
      (output_proj): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.3, inplace=False)
    )
    (text_visual_attn): CrossAttention(
      (query_proj): Linear(in_features=256, out_features=256, bias=True)
      (key_proj): Linear(in_features=256, out_features=256, bias=True)
      (value_proj): Linear(in_features=256, out_features=256, bias=True)
      (output_proj): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.3, inplace=False)
    )
    (audio_text_attn): CrossAttention(
      (query_proj): Linear(in_features=256, out_features=256, bias=True)
      (key_proj): Linear(in_features=256, out_features=256, bias=True)
      (value_proj): Linear(in_features=256, out_features=256, bias=True)
      (output_proj): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.3, inplace=False)
    )
    (audio_visual_attn): CrossAttention(
      (query_proj): Linear(in_features=256, out_features=256, bias=True)
      (key_proj): Linear(in_features=256, out_features=256, bias=True)
      (value_proj): Linear(in_features=256, out_features=256, bias=True)
      (output_proj): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.3, inplace=False)
    )
    (visual_text_attn): CrossAttention(
      (query_proj): Linear(in_features=256, out_features=256, bias=True)
      (key_proj): Linear(in_features=256, out_features=256, bias=True)
      (value_proj): Linear(in_features=256, out_features=256, bias=True)
      (output_proj): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.3, inplace=False)
    )
    (visual_audio_attn): CrossAttention(
      (query_proj): Linear(in_features=256, out_features=256, bias=True)
      (key_proj): Linear(in_features=256, out_features=256, bias=True)
      (value_proj): Linear(in_features=256, out_features=256, bias=True)
      (output_proj): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.3, inplace=False)
    )
    (fusion_layer): Sequential(
      (0): Linear(in_features=512, out_features=512, bias=True)
      (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (2): ReLU()
      (3): Dropout(p=0.3, inplace=False)
      (4): Linear(in_features=512, out_features=256, bias=True)
      (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (6): ReLU()
      (7): Dropout(p=0.3, inplace=False)
    )
    (output_proj): Linear(in_features=256, out_features=1, bias=True)
  )
  (output_proj): Linear(in_features=256, out_features=1, bias=True)
)
2025-04-23 17:36:22 - root - INFO - Logging to /Users/jugalgajjar/Documents/George Washington University/Semester 2/Machine Learning/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/logs/multimodal_fusion.log/log.txt
2025-04-23 17:36:22 - root - INFO - 
Starting training...
2025-04-23 17:36:22 - root - INFO - Starting training...
2025-04-23 17:36:22 - src.training.trainer - INFO - Starting training for 2 epochs
2025-04-23 17:36:22 - src.training.trainer - INFO - Model: TransformerFusionModel
2025-04-23 17:36:22 - src.training.trainer - INFO - Device: mps
2025-04-23 17:36:22 - src.training.trainer - INFO - Train samples: 2370
2025-04-23 17:36:22 - src.training.trainer - INFO - Validation samples: 264
2025-04-23 17:36:22 - src.training.trainer - INFO - Test samples: 658
2025-04-23 17:36:39 - src.training.trainer - INFO - Epoch 1 - Train loss: 0.0711
2025-04-23 17:37:06 - src.training.trainer - INFO - Epoch 1 - Validation loss: 0.0182
2025-04-23 17:37:06 - src.training.metrics - INFO - Epoch 1 - Val metrics:
2025-04-23 17:37:06 - src.training.metrics - INFO -   MAE: 0.1090
2025-04-23 17:37:06 - src.training.metrics - INFO -   Correlation: nan
2025-04-23 17:37:06 - src.training.metrics - INFO -   Binary Accuracy: 0.9659
2025-04-23 17:37:06 - src.training.metrics - INFO -   Binary F1: 0.9827
2025-04-23 17:37:06 - src.training.metrics - INFO -   7-class Accuracy: 0.9735
2025-04-23 17:37:06 - src.training.metrics - INFO -   7-class F1: 0.9604
2025-04-23 17:37:21 - src.training.metrics - INFO - Epoch 1 - Train metrics:
2025-04-23 17:37:21 - src.training.metrics - INFO -   MAE: 0.1126
2025-04-23 17:37:21 - src.training.metrics - INFO -   Correlation: 0.0000
2025-04-23 17:37:21 - src.training.metrics - INFO -   Binary Accuracy: 0.9494
2025-04-23 17:37:21 - src.training.metrics - INFO -   Binary F1: 0.9740
2025-04-23 17:37:21 - src.training.metrics - INFO -   7-class Accuracy: 0.9679
2025-04-23 17:37:21 - src.training.metrics - INFO -   7-class F1: 0.9522
2025-04-23 17:37:21 - src.training.trainer - INFO - Saved checkpoint to /Users/jugalgajjar/Documents/George Washington University/Semester 2/Machine Learning/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/models/multimodal_fusion_epoch_1.pt
2025-04-23 17:37:21 - src.training.trainer - INFO - Saved best model to /Users/jugalgajjar/Documents/George Washington University/Semester 2/Machine Learning/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/models/multimodal_fusion_best.pt
2025-04-23 17:37:21 - src.training.trainer - INFO - New best model at epoch 1
2025-04-23 17:37:37 - src.training.trainer - INFO - Epoch 2 - Train loss: 0.0591
2025-04-23 17:38:05 - src.training.trainer - INFO - Epoch 2 - Validation loss: 0.0201
2025-04-23 17:38:05 - src.training.metrics - INFO - Epoch 2 - Val metrics:
2025-04-23 17:38:05 - src.training.metrics - INFO -   MAE: 0.1062
2025-04-23 17:38:05 - src.training.metrics - INFO -   Correlation: nan
2025-04-23 17:38:05 - src.training.metrics - INFO -   Binary Accuracy: 0.9659
2025-04-23 17:38:05 - src.training.metrics - INFO -   Binary F1: 0.9827
2025-04-23 17:38:05 - src.training.metrics - INFO -   7-class Accuracy: 0.9735
2025-04-23 17:38:05 - src.training.metrics - INFO -   7-class F1: 0.9604
2025-04-23 17:38:19 - src.training.metrics - INFO - Epoch 2 - Train metrics:
2025-04-23 17:38:19 - src.training.metrics - INFO -   MAE: 0.1090
2025-04-23 17:38:19 - src.training.metrics - INFO -   Correlation: 0.0000
2025-04-23 17:38:19 - src.training.metrics - INFO -   Binary Accuracy: 0.9494
2025-04-23 17:38:19 - src.training.metrics - INFO -   Binary F1: 0.9740
2025-04-23 17:38:19 - src.training.metrics - INFO -   7-class Accuracy: 0.9679
2025-04-23 17:38:19 - src.training.metrics - INFO -   7-class F1: 0.9522
2025-04-23 17:38:19 - src.training.trainer - INFO - No improvement for 1 epochs
2025-04-23 17:38:20 - src.training.trainer - INFO - Saved checkpoint to /Users/jugalgajjar/Documents/George Washington University/Semester 2/Machine Learning/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/models/multimodal_fusion_epoch_2.pt
2025-04-23 17:38:20 - src.training.trainer - INFO - Training completed. Best model at epoch 1
2025-04-23 17:38:20 - root - INFO - Training completed in 117.72 seconds
2025-04-23 17:38:22 - root - INFO - Training curves plotted to /Users/jugalgajjar/Documents/George Washington University/Semester 2/Machine Learning/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/logs/multimodal_training_curves.png
2025-04-23 17:38:22 - root - INFO - Evaluating on test set...
2025-04-23 17:38:22 - src.training.trainer - INFO - Evaluating model on test set...
2025-04-23 17:38:37 - src.training.metrics - INFO - Test metrics:
2025-04-23 17:38:37 - src.training.metrics - INFO -   MAE: 0.1034
2025-04-23 17:38:37 - src.training.metrics - INFO -   Correlation: nan
2025-04-23 17:38:37 - src.training.metrics - INFO -   Binary Accuracy: 0.9544
2025-04-23 17:38:37 - src.training.metrics - INFO -   Binary F1: 0.9767
2025-04-23 17:38:37 - src.training.metrics - INFO -   7-class Accuracy: 0.9787
2025-04-23 17:38:37 - src.training.metrics - INFO -   7-class F1: 0.9682
2025-04-23 17:38:37 - src.training.metrics - INFO - Test metrics:
2025-04-23 17:38:37 - src.training.metrics - INFO -   MAE: 0.1034
2025-04-23 17:38:37 - src.training.metrics - INFO -   Correlation: nan
2025-04-23 17:38:37 - src.training.metrics - INFO -   Binary Accuracy: 0.9544
2025-04-23 17:38:37 - src.training.metrics - INFO -   Binary F1: 0.9767
2025-04-23 17:38:37 - src.training.metrics - INFO -   7-class Accuracy: 0.9787
2025-04-23 17:38:37 - src.training.metrics - INFO -   7-class F1: 0.9682
2025-04-23 17:38:53 - root - INFO - Prediction scatter plot saved to /Users/jugalgajjar/Documents/George Washington University/Semester 2/Machine Learning/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/logs/multimodal_predictions.png
2025-04-23 17:38:53 - root - INFO - Training and evaluation completed!
2025-04-23 17:38:59 - __main__ - INFO - Opening training curves: /Users/jugalgajjar/Documents/George Washington University/Semester 2/Machine Learning/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/logs/multimodal_training_curves.png
2025-04-23 17:38:59 - __main__ - ERROR - Prediction scatter plot not found.
2025-04-23 17:39:05 - __main__ - INFO - Exiting the console. Goodbye!
